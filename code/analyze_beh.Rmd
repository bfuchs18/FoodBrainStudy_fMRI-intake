---
title: "Behavioral Analyses"
author: "baf44"
date: "2/1/2024"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code to plot and analyze in-scanner behavioral data (% wanting).

This code uses the following derivative file:

BIDS/derivatives/preprocessed/task-foodcue_summary.tsv
    This contains long summary data (by block) for behavior during the foodcue task
    This was generated by BIDS/code/foodcue_proc/p0_getbehavioral.py

# Setup

```{r imports, include=FALSE}
# library(lme4) # used to run mixed effects models with lmer() -- loaded by sourced files
# library(lmerTest) # used to get p-values with anova() -- loaded by sourced files
# library(dplyr) # used for data wrangling -- loaded by sourced files
library(data.table) #used to subset with setDT()
library(emmeans) # used to get estimated marginal means with emmeans()
library(stringr) #used to clean betas dataframe with str_trim()

# import behavioral data
beh_all <- read.delim("BIDS/derivatives/preprocessed/beh/task-foodcue_summary.tsv") 

source("code/gen_fmri_index.R") # this sources setup_data.R, feis_portionsize.R, gen_fmri_covtable.R, determine_analysis_sample.R

# import and clean cerebellum betas
betas <- read.delim("~/Library/CloudStorage/OneDrive-ThePennsylvaniaStateUniversity/a-bari/00_PennState/Projects/FoodBrainStudy_fMRI-intake/BIDS/derivatives/analyses/foodcue-paper2/level2/feis_cerebellum/ped_fd-0.9_b20_3runs_noGSR_08-25-23/cerebellum_betas.txt")

# set column names
colnames(betas)[1] <- "id" #set column name
colnames(betas)[2] <- "betas_str" #set column name
betas$id <- sprintf("%03d", betas$id)

# remove white space at start of string, remove spaces, make numeric
betas$betas <- as.numeric(sub(" .*", "", str_trim(betas$betas_str)))

```

Prepare dataframe of in-scanner behavior (p_want)

```{r prep beh dataset}
# remove condition letter (A-F) from block_proc 
beh_all$block_proc <- substring(beh_all$block_proc, 2)

# Add portion_size and cue-type columns
beh_all$portion_size <- ifelse(grepl("Large", beh_all$cond), "Larger", "Smaller")
beh_all$energy_density <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "NA"))
beh_all$cue_type <- ifelse(grepl("High", beh_all$cond), "food", 
                       ifelse(grepl("Low", beh_all$cond), "food", "office"))

# create food-only dataframe by removing office conditions
beh_food<-beh_all[!(beh_all$cue_type=="office"),]

# calculate percentage from proportion
beh_food$percent_want_of_resp <- beh_food$p_want_of_resp*100

# convert run to integer
beh_food$run <- as.integer(beh_food$run)

# convert id column to string with leading zeros
beh_food$id <- sprintf("%03d", beh_food$id)

# subset to included in analyses - full sample (N = 63)
beh_food_fullsample <- setDT(beh_food)[id %chin% subset_lin_cer_b20$sub]

# subset to included in analyses - quad cerebellum sample
beh_food_quadcer_sample <- setDT(beh_food)[id %chin% subset_quad_cer_b20$sub]

```

# Behavioral analyses

Behavior is assessed for the full analysis sample (n=63).

Response rate
``` {r response rate analyses}

# Group the dataset by subject_id and then calculate response rate for each subject
response_rates <- beh_food_fullsample %>%
  group_by(id) %>%
  summarise(response_rate = sum(n_responses) / sum(n_trials))

# filter out response rates of 0 (technical errors)
response_rates_nozeros <- response_rates %>%
  filter(response_rate > 0)

# plot histograms of response rates
hist(response_rates$response_rate)
hist(response_rates_nozeros$response_rate)

# Calculate descriptive stats (mean, Q1, Q3) for non-zero response rates
quantiles_without_zeros <- response_rates_nozeros %>%
  summarise(
    q25 = quantile(response_rate, 0.25),
    median = median(response_rate),
    q75 = quantile(response_rate, 0.75)
  )

# View the results
print(quantiles_without_zeros)
```

Percent_want_of_resp by food portion size
``` {r mixed effects model analyses}

# percent_want_of_resp ~ food portion size (large, small)
lmer_perc_want_byPS = lmer(percent_want_of_resp ~ portion_size + run + (1 | id), data = beh_food_fullsample)
anova(lmer_perc_want_byPS)

# extract estimated marginal means
emmeans(lmer_perc_want_byPS, specs = "portion_size", type = "response")

```

# Correlation with cerebellar response

``` {r }

# compute the average difference in %want for larger and smaller portion sizes
difference_scores_all_blocks <- beh_food_quadcer_sample %>%
  group_by(id) %>%
  summarise(avg_diff_wanting_allblocks = mean(percent_want_of_resp[portion_size == "Larger"], na.rm = TRUE) - mean(percent_want_of_resp[portion_size == "Smaller"], na.rm = TRUE))


# merge dataframes
betas <- merge(betas, difference_scores_all_blocks, by = "id", all=T)

# correlation between cerebellar response to portion size (large - small) and average difference in wanting for large - small portion sizes
cor.test(x = betas$betas, y = betas$avg_diff_wanting_allblocks)
```
